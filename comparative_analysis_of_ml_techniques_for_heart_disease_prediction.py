# -*- coding: utf-8 -*-
"""Comparative_Analysis_of_ML_Techniques_for_Heart_Disease_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fgxIiPjiDUWxKuFtDYtpa4IT_-Al_Ser
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
sns.set_style("whitegrid")
plt.style.use("fivethirtyeight")

data = pd.read_csv('/content/heart.csv')
data.head()

data.shape

data.describe()

"""# EDA"""

class_counts = data['target'].value_counts()
print(class_counts)
data.target.value_counts().plot(kind="bar", color=["red", "blue"])

# Checking for missing values
data.isna().sum()

"""Dataset have no missing value"""

categorical_val = []
continous_val = []
for column in data.columns:
    print('---------------------------------------------------')
    print(f"{column} : {data[column].unique()}")
    if len(data[column].unique()) <= 10:
        categorical_val.append(column)
    else:
        continous_val.append(column)

plt.figure(figsize=(15, 15))
for i, column in enumerate(categorical_val, 1):
    plt.subplot(3, 3, i)
    data[data["target"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)
    data[data["target"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)
    plt.legend()
    plt.xlabel(column)

"""Observations from the above plot:

* cp {Chest pain}: People with cp 1, 2, 3 are more likely to have heart disease than people with cp 0.
* restecg {resting EKG results}: People with a value of 1 (reporting an abnormal heart rhythm, which can range from mild symptoms to severe problems) are more likely to have heart disease.
* exang {exercise-induced angina}: people with a value of 0 (No ==> angina induced by exercise) have more heart disease than people with a value of 1 (Yes ==> angina induced by exercise)
* slope {the slope of the ST segment of peak exercise}: People with a slope value of 2 (Downslopins: signs of an unhealthy heart) are more likely to have heart disease than people with a slope value of 2 slope is 0 (Upsloping: best heart rate with exercise) or 1 (Flatsloping: minimal change (typical healthy heart)).
* ca {number of major vessels (0-3) stained by fluoroscopy}: the more blood movement the better, so people with ca equal to 0 are more likely to have heart disease.
* thal {thalium stress result}: People with a thal value of 2 (defect corrected: once was a defect but ok now) are more likely to have heart disease.
"""

# Let's make our correlation matrix a little prettier
corr_matrix = data.corr()
fig, ax = plt.subplots(figsize=(15, 15))
ax = sns.heatmap(corr_matrix,
                 annot=True,
                 linewidths=0.5,
                 fmt=".2f",
                 cmap="Reds");
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)

data.drop('target', axis=1).corrwith(data.target).plot(kind='bar', grid=True, figsize=(12, 5),
                                                   title="Correlation with target")

"""* fbs and chol are the least correlated with the target variable.
* All other variables have a significant correlation with the target variable.
"""

# Preprocess the data
s_sc = StandardScaler()
col_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
data[col_to_scale] = s_sc.fit_transform(data[col_to_scale])

data.head()

X = data.drop('target', axis=1)
y = data.target
#  splitting the dataset to train and test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Function to evaluate different ML models
def evaluate_model(model, X_train, y_train, cv):
    # Perform 10-fold cross-validation and compute average scores
    cv_accuracy = np.mean(cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy'))
    cv_precision = np.mean(cross_val_score(model, X_train, y_train, cv=cv, scoring='precision'))
    cv_recall = np.mean(cross_val_score(model, X_train, y_train, cv=cv, scoring='recall'))
    cv_f1 = np.mean(cross_val_score(model, X_train, y_train, cv=cv, scoring='f1'))

    return cv_accuracy, cv_precision, cv_recall, cv_f1

models = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Support Vector Machine': SVC(),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'XG-Boost Classifier': XGBClassifier()
}

# Evaluate each model and print the results for 10-fold cross validation
def final(models, cv):
  print(f'With {cv}-fold cross-validation')
  for model_name, model in models.items():
      cv_accuracy, cv_precision, cv_recall, cv_f1 = evaluate_model(model, X_train, y_train, cv)
      print(f"Model: {model_name}")
      print(f"Average Cross-Validation Accuracy: {cv_accuracy*100:.2f}%")
      print(f"Average Cross-Validation Precision: {cv_precision*100:.2f}%")
      print(f"Average Cross-Validation Recall: {cv_recall*100:.2f}%")
      print(f"Average Cross-Validation F1 Score: {cv_f1*100:.2f}%")
      print("_" * 50)

# With 5-fold cross-validation
final(models, cv=5)

# With 10-fold cross-validation
final(models, cv=10)

# Train the best model (you can choose the model based on cross-validation results)
best_model = SVC()
best_model.fit(X_train, y_train)

# Test the best model on the test set
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Best Model (Support Vector Machine) Test Results:")
print(f"Accuracy: {accuracy*100:.2f}%")
print(f"Precision: {precision*100:.2f}%")
print(f"Recall: {recall*100:.2f}%")
print(f"F1 Score: {f1*100:.2f}%")



